import{_ as i}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as n,a as r,d as a,e,o as p}from"./app-DUUFD-Sg.js";const s={};function l(o,t){return p(),n("div",null,t[0]||(t[0]=[r('<h1 id="机器学习" tabindex="-1"><a class="header-anchor" href="#机器学习"><span>机器学习</span></a></h1><h2 id="基础或专业术语" tabindex="-1"><a class="header-anchor" href="#基础或专业术语"><span>基础或专业术语</span></a></h2><h3 id="数据集-training-set" tabindex="-1"><a class="header-anchor" href="#数据集-training-set"><span>数据集(Training Set)</span></a></h3>',3),a("p",null,[e('用于训练模型的数据集合，一般具有输入特征（x = "input" variable feature）输出特征（y = "output" variable or "target" variable）序号（m = number of training examples）。输入输出构成一条训练数据（x，y） = single training examples。（x，y）之上可以加上^(i)，用于表示这是第几个训练数据：比如'),a("br"),e(" $$(x"),a("sup",{"(i)":""},"{(i)},y"),e(") = i^{th} \\text{,,training example}$$")],-1),r('<h3 id="输入输出和函数" tabindex="-1"><a class="header-anchor" href="#输入输出和函数"><span>输入输出和函数</span></a></h3><p>机器学习中函数（Model）一般用f表示，输入（feature）常为x，真实输出为y，我们预测的输出（prediction）为$\\hat{y}$（表示输入x通过函数的预测输出值）</p><h3 id="如何计算模型f" tabindex="-1"><a class="header-anchor" href="#如何计算模型f"><span>如何计算模型f</span></a></h3><p>我们以线性模型举例：$f_{w,b}(x) = wx + b$ 我们要求模型f，实际就是要求w和b（即模型参数或者权重）的值。w和b一般就是基于x和$\\hat{y}$来求得。</p><h3 id="代价函数公式-cost-function也可以叫成本函数" tabindex="-1"><a class="header-anchor" href="#代价函数公式-cost-function也可以叫成本函数"><span>代价函数公式（cost function也可以叫成本函数）</span></a></h3>',5),a("p",null,[e("$\\hat{y} = f_{w,b}(x^{(i)})$或者$f_{w,b} = wx^{(i)}+b$"),a("br"),e(" 所以我们要找到w,b满足：$\\text{对于所有的}(x"),a("sup",{"(i)":""},"{(i)},y"),e(")\\text{都有}\\hat{y}接近y^{(i)}$"),a("br"),e(" 代价函数就是来计算当前预测值$\\hat{y}$和真实值y之间的差异."),a("br"),e(" 常用的是平方误差代价函数：$$J(w,b) = \\frac{1}{2m}\\sum_{i = 1}^m(y - \\hat{y})^2$$"),a("br"),e(" 或者$$J(w, b) = \\frac{1}{2m} \\sum_{i=1}^{m} (f_{w,b}(x^{(i)}) - y"),a("sup",null,"{(i)})"),e("2$$"),a("br"),e(" 这里使用2m是为了让计算更简洁，后续求权重偏导的过程中会出现一个2，在这里正好可以约去。"),a("br"),e(" 我们求模型的目标也就是让这个J尽可能地合理地小一些."),a("br"),e(" 所以不同的权重比如w,b会有不同的J，J值与权重的映射又组成了一个函数，我们需要在这个函数中寻找J最小值所对应的权重。")],-1),r('<h4 id="可视化代价函数" tabindex="-1"><a class="header-anchor" href="#可视化代价函数"><span>可视化代价函数</span></a></h4><p>可以建立一个3D图，或者使用等高线来表示。</p><h3 id="梯度下降-gradient-decent" tabindex="-1"><a class="header-anchor" href="#梯度下降-gradient-decent"><span>梯度下降（gradient decent）</span></a></h3><p>所以我们要找到合适的权重就是要找到尽可能小并且合适的J，那么这就需要用一个代码可编写的算法来寻找，这就是梯度下降算法。<br> 我的理解就是，从J函数某个位置开始作为起点，根据导数去寻找J的最小值（导数为0），要注意的是，J函数可能有多个极小值点，所以不同的起点找到的值可能不同。<br> 算法函数：<br> $$w = w - \\alpha \\frac{\\partial}{\\partial w} J(w, b)$$<br> $w$: 权重参数 (Weight)。左侧的 $w$ 是更新后的值，右侧是当前值。<br> $\\alpha$ (Alpha): 学习率 (Learning rate)。它决定了我们沿着梯度方向“迈步”的大小。$\\frac{\\partial}{\\partial w} J(w, b)$: 偏导数 (Derivative)。它代表了代价函数 $J$ 在当前 $w$ 点处的斜率，指明了函数值上升最快的方向。<br> 同理对于其他权重，比如b也有：<br> $$w = w - \\alpha \\frac{\\partial}{\\partial b} J(w, b)$$<br> 要注意的是在实际的梯度下降过程中，所有的权重是同步变化的，变化顺序就要准确获取，如下：<br><img src="https://i.imgs.ovh/2026/01/23/yqZ6tO.png" alt="yqZ6tO.png" loading="lazy"><br> 可见w和b是同步更新的，而不是一个更新再应用到另一个</p><h3 id="学习率-alpha" tabindex="-1"><a class="header-anchor" href="#学习率-alpha"><span>学习率$\\alpha$</span></a></h3>',5),a("p",null,[e("可以理解为步长，即每次梯度下降的变化量大小。如果学习率比较大，那么值在进行梯度下降的时候一次走的值就会很大，可能会跳过一些合适的值；但是如果学习率很小，每次走的步长很小，寻找过程就会很慢。"),a("br"),e(" 所以我们应该寻找一个合适的学习率，或者让学习率能够采用自适应策略：因为越接近J的最小值，导数会越小，那么此时走的步长就应该小一些，此时可以让学习率根据导数的大小来变化。"),a("br"),e(" 利用上述公式进行计算："),a("br"),e(" $$"),a("br"),e(" \\begin{aligned}"),a("br"),e(" \\frac{\\partial}{\\partial w} J(w, b) &= \\frac{\\partial}{\\partial w} \\frac{1}{2m} \\sum_{i=1}^{m} (f_{w,b}(x^{(i)}) - y"),a("sup",null,"{(i)})"),e("2 \\"),a("br"),e(" &= \\frac{1}{2m} \\sum_{i=1}^{m} \\frac{\\partial}{\\partial w} (wx^{(i)} + b - y"),a("sup",null,"{(i)})"),e("2 \\"),a("br"),e(" &= \\frac{1}{2m} \\sum_{i=1}^{m} 2(wx^{(i)} + b - y^{(i)}) \\cdot x^{(i)} \\"),a("br"),e(" &= \\frac{1}{m} \\sum_{i=1}^{m} (f_{w,b}(x^{(i)}) - y"),a("sup",{"(i)":""},"{(i)})x"),a("br"),e(" \\end{aligned}"),a("br"),e(" $$"),a("br"),e(" $$"),a("br"),e(" \\begin{aligned}"),a("br"),e(" \\frac{\\partial}{\\partial b} J(w, b) &= \\frac{\\partial}{\\partial b} \\frac{1}{2m} \\sum_{i=1}^{m} (f_{w,b}(x^{(i)}) - y"),a("sup",null,"{(i)})"),e("2 \\"),a("br"),e(" &= \\frac{1}{2m} \\sum_{i=1}^{m} 2(wx^{(i)} + b - y^{(i)}) \\cdot 1 \\"),a("br"),e(" &= \\frac{1}{m} \\sum_{i=1}^{m} (f_{w,b}(x^{(i)}) - y^{(i)})"),a("br"),e(" \\end{aligned}"),a("br"),e(" $$")],-1),r('<h2 id="监督学习-supervised-learning-带有输入x和输出y" tabindex="-1"><a class="header-anchor" href="#监督学习-supervised-learning-带有输入x和输出y"><span>监督学习（Supervised learning 带有输入x和输出y）</span></a></h2><ul><li><strong>回归算法（Regression Model）</strong>（常用于预测数据，输出有无数种可能）</li><li><strong>分类算法(Classification Model)</strong>（顾名思义，用于分类，预测出的数据即为类别,少数可能的输出）</li></ul><h3 id="线性回归模型-liner-regression-model-监督学习中的回归算法" tabindex="-1"><a class="header-anchor" href="#线性回归模型-liner-regression-model-监督学习中的回归算法"><span>线性回归模型（Liner Regression Model）（监督学习中的回归算法）</span></a></h3><p>输入只有一个维度，比方说房子的大小，输出也是一个维度，比方说房价。房价与房子大小之间的关系可以用一条线性函数来表示，通过两者关系的数据集可以拟合出一条合理的线性模型，这条线性模型就可以用来预测房价，即属于回归算法，</p><h2 id="无监督学习-unsupervised-learning-只有输入x没有输出y-没有数据监督" tabindex="-1"><a class="header-anchor" href="#无监督学习-unsupervised-learning-只有输入x没有输出y-没有数据监督"><span>无监督学习（Unsupervised learning 只有输入x没有输出y，没有数据监督）</span></a></h2><ul><li>聚类算法（自己根据特征将其进行分类）</li><li>异常检测 （根据输入数据的特征寻找出异常的数据）</li><li>降维（将一个大的数据集压缩到小的数据集，但是尽可能多的保留信息）</li></ul>',6)]))}const b=i(s,[["render",l]]),d=JSON.parse('{"path":"/posts/graduation/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html","title":"机器学习","lang":"zh-CN","frontmatter":{"icon":"pen-to-square","date":"2026-01-06T00:00:00.000Z","category":["毕业设计"],"tag":["机器学习"],"description":"机器学习 基础或专业术语 数据集(Training Set) 用于训练模型的数据集合，一般具有输入特征（x = \\"input\\" variable feature）输出特征（y = \\"output\\" variable or \\"target\\" variable）序号（m = number of training examples）。输入输出构成一条训练数据...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"机器学习\\",\\"image\\":[\\"https://i.imgs.ovh/2026/01/23/yqZ6tO.png\\"],\\"datePublished\\":\\"2026-01-06T00:00:00.000Z\\",\\"dateModified\\":\\"2026-01-23T10:42:36.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Jing104\\",\\"url\\":\\"https://jing104.blog\\"}]}"],["meta",{"property":"og:url","content":"https://jing104.blog/posts/graduation/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html"}],["meta",{"property":"og:site_name","content":"Jing104-Note"}],["meta",{"property":"og:title","content":"机器学习"}],["meta",{"property":"og:description","content":"机器学习 基础或专业术语 数据集(Training Set) 用于训练模型的数据集合，一般具有输入特征（x = \\"input\\" variable feature）输出特征（y = \\"output\\" variable or \\"target\\" variable）序号（m = number of training examples）。输入输出构成一条训练数据..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://i.imgs.ovh/2026/01/23/yqZ6tO.png"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2026-01-23T10:42:36.000Z"}],["meta",{"property":"article:tag","content":"机器学习"}],["meta",{"property":"article:published_time","content":"2026-01-06T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2026-01-23T10:42:36.000Z"}]]},"git":{"createdTime":1767776901000,"updatedTime":1769164956000,"contributors":[{"name":"Jing104","username":"Jing104","email":"2046485376@qq.com","commits":2,"url":"https://github.com/Jing104"}]},"readingTime":{"minutes":4.8,"words":1440},"filePathRelative":"posts/graduation/机器学习.md","excerpt":"\\n<h2>基础或专业术语</h2>\\n<h3>数据集(Training Set)</h3>\\n<p>用于训练模型的数据集合，一般具有输入特征（x = \\"input\\" variable feature）输出特征（y = \\"output\\" variable or \\"target\\" variable）序号（m = number of training examples）。输入输出构成一条训练数据（x，y） = single training examples。（x，y）之上可以加上^(i)，用于表示这是第几个训练数据：比如<br>\\n$$(x<sup (i)=\\"\\">{(i)},y</sup>) = i^{th} \\\\text{,,training example}$$</p>","autoDesc":true}');export{b as comp,d as data};
